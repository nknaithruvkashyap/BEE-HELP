# -*- coding: utf-8 -*-
"""ClassificationAlgo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oF29fRJ6ZJ8JtkFIQZ00LytGN40PH8-R
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import joblib
import librosa
import librosa.display
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Mount Google Drive
drive.mount('/content/drive')
# %cd '/content/drive/MyDrive/Colab Notebooks/BeeProject25'

# Load CSV file
csv_path = 'all_data_updatedd.csv'
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"CSV file not found: {csv_path}")
labels_df = pd.read_csv(csv_path)
print("CSV sample:")
print(labels_df.head())
print("Unique file names in CSV:", labels_df['file name'].nunique())

# Define paths
image_folder = 'sound_files/spectrogramss'  # Updated folder name
target_size = (100, 40)  # Image resize dimensions

def list_image_files(image_folder):
    all_files = set(os.listdir(image_folder))
    print(f"Total spectrogram files found: {len(all_files)}")
    return all_files

def propagate_labels(labels_df, image_folder):
    spectrogram_data = []
    all_files = list_image_files(image_folder)

    for _, row in labels_df.iterrows():
        raw_file = row['file name']
        queen_presence = row['queen presence']
        base_name = os.path.splitext(raw_file)[0]

        valid_sections = [f'Copy of {base_name}__segment{sec}.png' for sec in range(6) if f'Copy of {base_name}__segment{sec}.png' in all_files]

        for spectrogram in valid_sections:
            spectrogram_data.append((os.path.join(image_folder, spectrogram), queen_presence))

    return pd.DataFrame(spectrogram_data, columns=['file_path', 'label'])

spectrogram_df = propagate_labels(labels_df, image_folder)

if spectrogram_df.empty:
    raise ValueError("No matching spectrograms found. Check file names.")

def augment_image(image):
    new_size = (np.random.randint(80, 100), np.random.randint(30, 40))
    augmented_image = image.resize(new_size).resize(target_size)

    # Ensure noise shape matches resized image
    augmented_array = np.array(augmented_image)
    noise = np.random.normal(0, 10, augmented_array.shape)  # Match shape dynamically
    augmented_image = Image.fromarray(np.clip(augmented_array + noise, 0, 255).astype(np.uint8))

    return augmented_image

def load_images_and_labels(spectrogram_df, target_size):
    images, labels = [], []
    for _, row in spectrogram_df.iterrows():
        image = Image.open(row['file_path']).convert('L').resize(target_size)
        images.append(np.array(image).flatten())
        labels.append(row['label'])

        augmented_image = augment_image(image)
        images.append(np.array(augmented_image).flatten())
        labels.append(row['label'])

    return np.array(images) / 255.0, np.array(labels)

X, y = load_images_and_labels(spectrogram_df, target_size)

# Normalize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Define and train MLP Classifier
clf = MLPClassifier(
    hidden_layer_sizes=(20,),  # Single hidden layer with 20 neurons for moderate complexity
    max_iter=30,  # Limits training to 30 epochs, may stop early if early_stopping is triggered
    solver='sgd',  # Uses Stochastic Gradient Descent for weight updates
    learning_rate_init=0.005,  # Initial learning rate, small values allow gradual learning
    alpha=0.05,  # L2 regularization strength to prevent overfitting
    early_stopping=True  # Stops training when validation loss stops improving
)
clf.fit(X_train, y_train)

# Save the trained model and scaler
joblib.dump(clf, "queenlessness_model.pkl")
joblib.dump(scaler, "scaler.pkl")

def process_audio_file(audio_path, target_size):
    # Load audio file
    y, sr = librosa.load(audio_path, sr=None)  # Keep original sampling rate

    # Convert to spectrogram
    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)
    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)  # Convert to dB scale

    # Resize spectrogram to match model input
    spectrogram = Image.fromarray(spectrogram).resize(target_size).convert('L')

    # Convert to numpy array and flatten
    spectrogram_array = np.array(spectrogram).flatten().reshape(1, -1)  # Make it a 2D array

    # Load previously saved scaler and normalize
    scaler = joblib.load("scaler.pkl")
    spectrogram_array = scaler.transform(spectrogram_array)

    return spectrogram_array

def predict_new_audio(audio_path):
    # Load trained model
    clf = joblib.load("queenlessness_model.pkl")

    # Process the audio file
    spectrogram_array = process_audio_file(audio_path, target_size)

    # Run prediction
    prediction = clf.predict(spectrogram_array)

    # Output result
    if prediction[0] == 1:
        print("Prediction: Queen Present üêùüëë")
    else:
        print("Prediction: Queenless Hive ‚ö†Ô∏è")

# Example usage:
predict_new_audio("DummyFolder/CJ001 - Missing Queen - Day -  (100).wav")

